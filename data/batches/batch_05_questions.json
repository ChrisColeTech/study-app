{
  "metadata": {
    "batch_number": 5,
    "total_batches": 7,
    "questions_in_batch": 25,
    "question_range": "151-175",
    "instructions": {
      "task": "Answer each AWS SAA-C03 exam question with the correct letter choice(s)",
      "format": "Provide correct_answer and explanation for each question",
      "output_format": "JSON with ai_answers array",
      "example_output": {
        "ai_answers": [
          {
            "question_number": 36,
            "correct_answer": "B",
            "explanation": "Multi-Region KMS key provides least operational overhead for cross-region encryption."
          }
        ]
      }
    }
  },
  "questions": [
    {
      "question_number": 151,
      "question_text": "A company wants to migrate its on-premises data center to AWS. According to the company's compliance requirements, the company can use\nonly the ap-northeast-3 Region. Company administrators are not permitted to connect VPCs to the internet.\nWhich solutions will meet these requirements? (Choose two.)",
      "options": [
        [
          "A",
          "Use AWS Control Tower to implement data residency guardrails to deny internet access and deny access to all AWS Regions except ap-"
        ],
        [
          "B",
          "Use rules in AWS WAF to prevent internet access. Deny access to all AWS Regions except ap-northeast-3 in the AWS account settings."
        ],
        [
          "C",
          "Use AWS Organizations to con\u0000gure service control policies (SCPS) that prevent VPCs from gaining internet access. Deny access to all"
        ],
        [
          "D",
          "Create an outbound rule for the network ACL in each VPC to deny all tra\u0000c from 0.0.0.0/0. Create an IAM policy for each user to prevent"
        ],
        [
          "E",
          "Use AWS Con\u0000g to activate managed rules to detect and alert for internet gateways and to detect and alert for new resources deployed"
        ]
      ],
      "question_type": "multiple_choice_2",
      "expected_answers": 2,
      "topic": "Security & Identity",
      "aws_services": [
        "COMPLIANCE"
      ]
    },
    {
      "question_number": 152,
      "question_text": "A company uses a three-tier web application to provide training to new employees. The application is accessed for only 12 hours every day. The\ncompany is using an Amazon RDS for MySQL DB instance to store information and wants to minimize costs.\nWhat should a solutions architect do to meet these requirements?",
      "options": [
        [
          "A",
          "Con\u0000gure an IAM policy for AWS Systems Manager Session Manager. Create an IAM role for the policy. Update the trust relationship of the"
        ],
        [
          "B",
          "Create an Amazon ElastiCache for Redis cache cluster that gives users the ability to access the data from the cache when the DB instance"
        ],
        [
          "C",
          "Launch an Amazon EC2 instance. Create an IAM role that grants access to Amazon RDS. Attach the role to the EC2 instance. Con\u0000gure a"
        ],
        [
          "D",
          "Create AWS Lambda functions to start and stop the DB instance. Create Amazon EventBridge (Amazon CloudWatch Events) scheduled"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Databases",
      "aws_services": [
        "RDS",
        "MYSQL"
      ]
    },
    {
      "question_number": 153,
      "question_text": "A company sells ringtones created from clips of popular songs. The \u0000les containing the ringtones are stored in Amazon S3 Standard and are at\nleast 128 KB in size. The company has millions of \u0000les, but downloads are infrequent for ringtones older than 90 days. The company needs to\nsave money on storage while keeping the most accessed \u0000les readily available for its users.\nWhich action should the company take to meet these requirements MOST cost-effectively?",
      "options": [
        [
          "A",
          "Con\u0000gure S3 Standard-Infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects."
        ],
        [
          "B",
          "Move the \u0000les to S3 Intelligent-Tiering and con\u0000gure it to move objects to a less expensive storage tier after 90 days."
        ],
        [
          "C",
          "Con\u0000gure S3 inventory to manage objects and move them to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days."
        ],
        [
          "D",
          "Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-1A) after 90"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Storage Services",
      "aws_services": [
        "S3"
      ]
    },
    {
      "question_number": 154,
      "question_text": "A company needs to save the results from a medical trial to an Amazon S3 repository. The repository must allow a few scientists to add new \u0000les\nand must restrict all other users to read-only access. No users can have the ability to modify or delete any \u0000les in the repository. The company\nmust keep every \u0000le in the repository for a minimum of 1 year after its creation date.\nWhich solution will meet these requirements?",
      "options": [
        [
          "A",
          "Use S3 Object Lock in governance mode with a legal hold of 1 year."
        ],
        [
          "B",
          "Use S3 Object Lock in compliance mode with a retention period of 365 days."
        ],
        [
          "C",
          "Use an IAM role to restrict all users from deleting or changing objects in the S3 bucket. Use an S3 bucket policy to only allow the IAM role."
        ],
        [
          "D",
          "Con\u0000gure the S3 bucket to invoke an AWS Lambda function every time an object is added. Con\u0000gure the function to track the hash of the"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Storage Services",
      "aws_services": [
        "S3"
      ]
    },
    {
      "question_number": 155,
      "question_text": "A large media company hosts a web application on AWS. The company wants to start caching con\u0000dential media \u0000les so that users around the\nworld will have reliable access to the \u0000les. The content is stored in Amazon S3 buckets. The company must deliver the content quickly, regardless\nof where the requests originate geographically.\nWhich solution will meet these requirements?",
      "options": [
        [
          "A",
          "Use AWS DataSync to connect the S3 buckets to the web application."
        ],
        [
          "B",
          "Deploy AWS Global Accelerator to connect the S3 buckets to the web application."
        ],
        [
          "C",
          "Deploy Amazon CloudFront to connect the S3 buckets to CloudFront edge servers."
        ],
        [
          "D",
          "Use Amazon Simple Queue Service (Amazon SQS) to connect the S3 buckets to the web application."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Storage Services",
      "aws_services": [
        "S3"
      ]
    },
    {
      "question_number": 156,
      "question_text": "A company produces batch data that comes from different databases. The company also produces live stream data from network sensors and\napplication APIs. The company needs to consolidate all the data into one place for business analytics. The company needs to process the\nincoming data and then stage the data in different Amazon S3 buckets. Teams will later run one-time queries and import the data into a business\nintelligence tool to show key performance indicators (KPIs).\nWhich combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)",
      "options": [
        [
          "A",
          "Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs."
        ],
        [
          "B",
          "Use Amazon Kinesis Data Analytics for one-time queries. Use Amazon QuickSight to create dashboards for KPIs."
        ],
        [
          "C",
          "Create custom AWS Lambda functions to move the individual records from the databases to an Amazon Redshift cluster."
        ],
        [
          "D",
          "Use an AWS Glue extract, transform, and load (ETL) job to convert the data into JSON format. Load the data into multiple Amazon"
        ],
        [
          "E",
          "Use blueprints in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract"
        ]
      ],
      "question_type": "multiple_choice_2",
      "expected_answers": 2,
      "topic": "Messaging & Integration",
      "aws_services": [
        "ANALYTICS",
        "STAGE"
      ]
    },
    {
      "question_number": 157,
      "question_text": "A company stores data in an Amazon Aurora PostgreSQL DB cluster. The company must store all the data for 5 years and must delete all the data\nafter 5 years. The company also must inde\u0000nitely keep audit logs of actions that are performed within the database. Currently, the company has\nautomated backups con\u0000gured for Aurora.\nWhich combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
      "options": [
        [
          "A",
          "Take a manual snapshot of the DB cluster."
        ],
        [
          "B",
          "Create a lifecycle policy for the automated backups."
        ],
        [
          "C",
          "Con\u0000gure automated backup retention for 5 years."
        ],
        [
          "D",
          "Con\u0000gure an Amazon CloudWatch Logs export for the DB cluster."
        ],
        [
          "E",
          "Use AWS Backup to take the backups and to keep the backups for 5 years."
        ]
      ],
      "question_type": "multiple_choice_2",
      "expected_answers": 2,
      "topic": "Databases",
      "aws_services": [
        "POSTGRESQL",
        "CLUSTER",
        "AURORA"
      ]
    },
    {
      "question_number": 158,
      "question_text": "A solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then\nwill be available on demand. The event is expected to attract a global online audience.\nWhich service will improve the performance of both the real-time and on-demand streaming?",
      "options": [
        [
          "A",
          "Amazon CloudFront"
        ],
        [
          "B",
          "AWS Global Accelerator"
        ],
        [
          "C",
          "Amazon Route 53"
        ],
        [
          "D",
          "Amazon S3 Transfer Acceleration"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Messaging & Integration",
      "aws_services": [
        "STREAMING"
      ]
    },
    {
      "question_number": 159,
      "question_text": "A company is running a publicly accessible serverless application that uses Amazon API Gateway and AWS Lambda. The application’s tra\u0000c\nrecently spiked due to fraudulent requests from botnets.\nWhich steps should a solutions architect take to block requests from unauthorized users? (Choose two.)",
      "options": [
        [
          "A",
          "Create a usage plan with an API key that is shared with genuine users only."
        ],
        [
          "B",
          "Integrate logic within the Lambda function to ignore the requests from fraudulent IP addresses."
        ],
        [
          "C",
          "Implement an AWS WAF rule to target malicious requests and trigger actions to \u0000lter them out."
        ],
        [
          "D",
          "Convert the existing public API to a private API. Update the DNS records to redirect users to the new API endpoint."
        ],
        [
          "E",
          "Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call."
        ]
      ],
      "question_type": "multiple_choice_2",
      "expected_answers": 2,
      "topic": "Compute Services",
      "aws_services": [
        "LAMBDA",
        "SERVERLESS"
      ]
    },
    {
      "question_number": 160,
      "question_text": "An ecommerce company hosts its analytics application in the AWS Cloud. The application generates about 300 MB of data each month. The data\nis stored in JSON format. The company is evaluating a disaster recovery solution to back up the data. The data must be accessible in milliseconds\nif it is needed, and the data must be kept for 30 days.\nWhich solution meets these requirements MOST cost-effectively?",
      "options": [
        [
          "A",
          "Amazon OpenSearch Service (Amazon Elasticsearch Service)"
        ],
        [
          "B",
          "Amazon S3 Glacier"
        ],
        [
          "C",
          "Amazon S3 Standard"
        ],
        [
          "D",
          "Amazon RDS for PostgreSQL"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "COST"
      ]
    },
    {
      "question_number": 161,
      "question_text": "A company has a small Python application that processes JSON documents and outputs the results to an on-premises SQL database. The\napplication runs thousands of times each day. The company wants to move the application to the AWS Cloud. The company needs a highly\navailable solution that maximizes scalability and minimizes operational overhead.\nWhich solution will meet these requirements?",
      "options": [
        [
          "A",
          "Place the JSON documents in an Amazon S3 bucket. Run the Python code on multiple Amazon EC2 instances to process the documents."
        ],
        [
          "B",
          "Place the JSON documents in an Amazon S3 bucket. Create an AWS Lambda function that runs the Python code to process the documents"
        ],
        [
          "C",
          "Place the JSON documents in an Amazon Elastic Block Store (Amazon EBS) volume. Use the EBS Multi-Attach feature to attach the volume"
        ],
        [
          "D",
          "Place the JSON documents in an Amazon Simple Queue Service (Amazon SQS) queue as messages. Deploy the Python code as a container"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "GENERAL"
      ]
    },
    {
      "question_number": 162,
      "question_text": "A company wants to use high performance computing (HPC) infrastructure on AWS for \u0000nancial risk modeling. The company’s HPC workloads run\non Linux. Each HPC work\u0000ow runs on hundreds of Amazon EC2 Spot Instances, is short-lived, and generates thousands of output \u0000les that are\nultimately stored in persistent storage for analytics and long-term future use.\nThe company seeks a cloud storage solution that permits the copying of on-premises data to long-term persistent storage to make data available\nfor processing by all EC2 instances. The solution should also be a high performance \u0000le system that is integrated with persistent storage to read\nand write datasets and output \u0000les.\nWhich combination of AWS services meets these requirements?",
      "options": [
        [
          "A",
          "Amazon FSx for Lustre integrated with Amazon S3"
        ],
        [
          "B",
          "Amazon FSx for Windows File Server integrated with Amazon S3"
        ],
        [
          "C",
          "Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)"
        ],
        [
          "D",
          "Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "OUTPUT"
      ]
    },
    {
      "question_number": 163,
      "question_text": "A company is building a containerized application on premises and decides to move the application to AWS. The application will have thousands\nof users soon after it is deployed. The company is unsure how to manage the deployment of containers at scale. The company needs to deploy\nthe containerized application in a highly available architecture that minimizes operational overhead.\nWhich solution will meet these requirements?",
      "options": [
        [
          "A",
          "Store container images in an Amazon Elastic Container Registry (Amazon ECR) repository. Use an Amazon Elastic Container Service"
        ],
        [
          "B",
          "Store container images in an Amazon Elastic Container Registry (Amazon ECR) repository. Use an Amazon Elastic Container Service"
        ],
        [
          "C",
          "Store container images in a repository that runs on an Amazon EC2 instance. Run the containers on EC2 instances that are spread across"
        ],
        [
          "D",
          "Create an Amazon EC2 Amazon Machine Image (AMI) that contains the container image. Launch EC2 instances in an Auto Scaling group"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "GENERAL"
      ]
    },
    {
      "question_number": 164,
      "question_text": "A company has two applications: a sender application that sends messages with payloads to be processed and a processing application intended\nto receive the messages with payloads. The company wants to implement an AWS service to handle messages between the two applications. The\nsender application can send about 1,000 messages each hour. The messages may take up to 2 days to be processed: If the messages fail to\nprocess, they must be retained so that they do not impact the processing of any remaining messages.\nWhich solution meets these requirements and is the MOST operationally e\u0000cient?",
      "options": [
        [
          "A",
          "Set up an Amazon EC2 instance running a Redis database. Con\u0000gure both applications to use the instance. Store, process, and delete the"
        ],
        [
          "B",
          "Use an Amazon Kinesis data stream to receive the messages from the sender application. Integrate the processing application with the"
        ],
        [
          "C",
          "Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Con\u0000gure a dead-letter queue"
        ],
        [
          "D",
          "Subscribe the processing application to an Amazon Simple Noti\u0000cation Service (Amazon SNS) topic to receive noti\u0000cations to process."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "GENERAL"
      ]
    },
    {
      "question_number": 165,
      "question_text": "A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company’s\nsecurity policy requires that all website tra\u0000c be inspected by AWS WAF.\nHow should the solutions architect comply with these requirements?",
      "options": [
        [
          "A",
          "Con\u0000gure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only."
        ],
        [
          "B",
          "Con\u0000gure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin."
        ],
        [
          "C",
          "Con\u0000gure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront."
        ],
        [
          "D",
          "Con\u0000gure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Networking & Content Delivery",
      "aws_services": [
        "CLOUDFRONT",
        "ORIGIN"
      ]
    },
    {
      "question_number": 166,
      "question_text": "Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from\nusers around the world. The \u0000les are stored in an Amazon S3 bucket. A solutions architect has been asked to design an e\u0000cient and effective\nsolution.\nWhich action should the solutions architect take to accomplish this?",
      "options": [
        [
          "A",
          "Generate presigned URLs for the \u0000les."
        ],
        [
          "B",
          "Use cross-Region replication to all Regions."
        ],
        [
          "C",
          "Use the geoproximity feature of Amazon Route 53."
        ],
        [
          "D",
          "Use Amazon CloudFront with the S3 bucket as its origin."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Storage Services",
      "aws_services": [
        "S3",
        "BUCKET"
      ]
    },
    {
      "question_number": 167,
      "question_text": "A company runs a production application on a \u0000eet of Amazon EC2 instances. The application reads the data from an Amazon SQS queue and\nprocesses the messages in parallel. The message volume is unpredictable and often has intermittent tra\u0000c. This application should continually\nprocess messages without any downtime.\nWhich solution meets these requirements MOST cost-effectively?",
      "options": [
        [
          "A",
          "Use Spot Instances exclusively to handle the maximum capacity required."
        ],
        [
          "B",
          "Use Reserved Instances exclusively to handle the maximum capacity required."
        ],
        [
          "C",
          "Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity."
        ],
        [
          "D",
          "Use Reserved Instances for the baseline capacity and use On-Demand Instances to handle additional capacity."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Messaging & Integration",
      "aws_services": [
        "SQS",
        "QUEUE",
        "MESSAGE"
      ]
    },
    {
      "question_number": 168,
      "question_text": "A security team wants to limit access to speci\u0000c services or actions in all of the team’s AWS accounts. All accounts belong to a large organization\nin AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained.\nWhat should a solutions architect do to accomplish this?",
      "options": [
        [
          "A",
          "Create an ACL to provide access to the services or actions."
        ],
        [
          "B",
          "Create a security group to allow accounts and attach it to user groups."
        ],
        [
          "C",
          "Create cross-account roles in each account to deny access to the services or actions."
        ],
        [
          "D",
          "Create a service control policy in the root organizational unit to deny access to the services or actions."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "GENERAL"
      ]
    },
    {
      "question_number": 169,
      "question_text": "A company is concerned about the security of its public web application due to recent web attacks. The application uses an Application Load\nBalancer (ALB). A solutions architect must reduce the risk of DDoS attacks against the application.\nWhat should the solutions architect do to meet this requirement?",
      "options": [
        [
          "A",
          "Add an Amazon Inspector agent to the ALB."
        ],
        [
          "B",
          "Con\u0000gure Amazon Macie to prevent attacks."
        ],
        [
          "C",
          "Enable AWS Shield Advanced to prevent attacks."
        ],
        [
          "D",
          "Con\u0000gure Amazon GuardDuty to monitor the ALB."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Compute Services",
      "aws_services": [
        "ALB"
      ]
    },
    {
      "question_number": 170,
      "question_text": "A company’s web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy,\nwhich now requires the application to be accessed from one speci\u0000c country only.\nWhich con\u0000guration will meet this requirement?",
      "options": [
        [
          "A",
          "Con\u0000gure the security group for the EC2 instances."
        ],
        [
          "B",
          "Con\u0000gure the security group on the Application Load Balancer."
        ],
        [
          "C",
          "Con\u0000gure AWS WAF on the Application Load Balancer in a VPC."
        ],
        [
          "D",
          "Con\u0000gure the network ACL for the subnet that contains the EC2 instances."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Compute Services",
      "aws_services": [
        "EC2",
        "LOAD BALANCER",
        "APPLICATION LOAD BALANCER"
      ]
    },
    {
      "question_number": 171,
      "question_text": "A company provides an API to its users that automates inquiries for tax computations based on item prices. The company experiences a larger\nnumber of inquiries during the holiday season only that cause slower response times. A solutions architect needs to design a solution that is\nscalable and elastic.\nWhat should the solutions architect do to accomplish this?",
      "options": [
        [
          "A",
          "Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made."
        ],
        [
          "B",
          "Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax"
        ],
        [
          "C",
          "Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received"
        ],
        [
          "D",
          "Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance. API Gateway accepts and"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Monitoring & Management",
      "aws_services": [
        "GENERAL"
      ]
    },
    {
      "question_number": 172,
      "question_text": "A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is\nsensitive. The application uses HTTPS but needs another layer of security. The sensitive information should.be protected throughout the entire\napplication stack, and access to the information should be restricted to certain applications.\nWhich action should the solutions architect take?",
      "options": [
        [
          "A",
          "Con\u0000gure a CloudFront signed URL."
        ],
        [
          "B",
          "Con\u0000gure a CloudFront signed cookie."
        ],
        [
          "C",
          "Con\u0000gure a CloudFront \u0000eld-level encryption pro\u0000le."
        ],
        [
          "D",
          "Con\u0000gure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Policy."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Networking & Content Delivery",
      "aws_services": [
        "CLOUDFRONT",
        "DISTRIBUTION"
      ]
    },
    {
      "question_number": 173,
      "question_text": "A gaming company hosts a browser-based application on AWS. The users of the application consume a large number of videos and images that\nare stored in Amazon S3. This content is the same for all users.\nThe application has increased in popularity, and millions of users worldwide accessing these media \u0000les. The company wants to provide the \u0000les\nto the users while reducing the load on the origin.\nWhich solution meets these requirements MOST cost-effectively?",
      "options": [
        [
          "A",
          "Deploy an AWS Global Accelerator accelerator in front of the web servers."
        ],
        [
          "B",
          "Deploy an Amazon CloudFront web distribution in front of the S3 bucket."
        ],
        [
          "C",
          "Deploy an Amazon ElastiCache for Redis instance in front of the web servers."
        ],
        [
          "D",
          "Deploy an Amazon ElastiCache for Memcached instance in front of the web servers."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Storage Services",
      "aws_services": [
        "S3"
      ]
    },
    {
      "question_number": 174,
      "question_text": "A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone\nbehind an Application Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the\napplication.\nWhich architecture should the solutions architect choose that provides high availability?",
      "options": [
        [
          "A",
          "Create an Auto Scaling group that uses three instances across each of two Regions."
        ],
        [
          "B",
          "Modify the Auto Scaling group to use three instances across each of two Availability Zones."
        ],
        [
          "C",
          "Create an Auto Scaling template that can be used to quickly create more instances in another Region."
        ],
        [
          "D",
          "Change the ALB in front of the Amazon EC2 instances in a round-robin con\u0000guration to balance tra\u0000c to the web tier."
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Compute Services",
      "aws_services": [
        "EC2",
        "AUTO SCALING",
        "SCALING GROUP",
        "LOAD BALANCER",
        "APPLICATION LOAD BALANCER",
        "ALB"
      ]
    },
    {
      "question_number": 175,
      "question_text": "An ecommerce company has an order-processing application that uses Amazon API Gateway and an AWS Lambda function. The application\nstores data in an Amazon Aurora PostgreSQL database. During a recent sales event, a sudden surge in customer orders occurred. Some\ncustomers experienced timeouts, and the application did not process the orders of those customers.\nA solutions architect determined that the CPU utilization and memory utilization were high on the database because of a large number of open\nconnections. The solutions architect needs to prevent the timeout errors while making the least possible changes to the application.\nWhich solution will meet these requirements?",
      "options": [
        [
          "A",
          "Con\u0000gure provisioned concurrency for the Lambda function. Modify the database to be a global database in multiple AWS Regions."
        ],
        [
          "B",
          "Use Amazon RDS Proxy to create a proxy for the database. Modify the Lambda function to use the RDS Proxy endpoint instead of the"
        ],
        [
          "C",
          "Create a read replica for the database in a different AWS Region. Use query string parameters in API Gateway to route tra\u0000c to the read"
        ],
        [
          "D",
          "Migrate the data from Aurora PostgreSQL to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS). Modify the Lambda"
        ]
      ],
      "question_type": "single_choice",
      "expected_answers": 1,
      "topic": "Compute Services",
      "aws_services": [
        "LAMBDA",
        "FUNCTION"
      ]
    }
  ]
}